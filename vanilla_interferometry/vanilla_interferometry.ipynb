{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert, find_peaks, savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter\n",
    "from scipy.ndimage import grey_closing\n",
    "\n",
    "\"\"\"\n",
    "Imports and configuration\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "from scipy.interpolate import CubicSpline\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# Parameters (edit these to match your data locations)\n",
    "# Use Path for robust path handling across platforms\n",
    "# `myloc` from your script appended to the DAQ base\n",
    "sig_path = Path(r\"C:\\Users\\sann7609\\Documents\\Oxford\\ChannelAnalysis_CALA_Sept25_minisforum\\vanilla_interferometry\\for_vanilla_80mbar_Bdel582_t0\\Interferometry2\\sig\")\n",
    "bg_path  = Path(r\"C:\\Users\\sann7609\\Documents\\Oxford\\ChannelAnalysis_CALA_Sept25_minisforum\\vanilla_interferometry\\for_vanilla_80mbar_Bdel582_t0\\Interferometry2\\bg\")\n",
    "SIG_HEADER = '.tiff'   # substring common to signal image filenames\n",
    "BG_HEADER  = '.tiff'     # substring common to background image filenames\n",
    "\n",
    "# How many shots to process. By default we'll infer from files found.\n",
    "NUM_SHOTS: Optional[int] = 1  # set to an integer to limit processing\n",
    "\n",
    "# Display scaling for final image\n",
    "PHASE_DISPLAY_CLIM = (-0.05, 0.05)\n",
    "\n",
    "# Locate files\n",
    "\n",
    "sig_paths = sorted([p for p in sig_path.glob(f\"*{SIG_HEADER}*\")])\n",
    "bg_paths  = sorted([p for p in bg_path.glob(f\"*{BG_HEADER}*\")])\n",
    "\n",
    "print(f\"Found {len(sig_paths)} signal files and {len(bg_paths)} background files in {sig_path}\")\n",
    "\n",
    "# Optionally limit number of shots\n",
    "if NUM_SHOTS is not None:\n",
    "    sig_paths = sig_paths[:NUM_SHOTS]\n",
    "    bg_paths  = bg_paths[:NUM_SHOTS]\n",
    "\n",
    "# Sanity check: at least one file\n",
    "if len(sig_paths) == 0:\n",
    "    raise FileNotFoundError(f\"No signal files found using pattern *{SIG_HEADER}* in {sig_path}\")\n",
    "\n",
    "\n",
    "# Read a single image to get frame shape (handle color/grayscale)\n",
    "from imageio import imread\n",
    "\n",
    "first_img = imread(sig_paths[0])\n",
    "print(\"First image shape (as read):\", first_img.shape)\n",
    "\n",
    "# If color (H,W,3) convert to grayscale by luminosity method\n",
    "if first_img.ndim == 3:\n",
    "    frameshape = (first_img.shape[0], first_img.shape[1])\n",
    "else:\n",
    "    frameshape = first_img.shape\n",
    "\n",
    "print(\"Frame shape (H, W):\", frameshape)\n",
    "\n",
    "# Read all files into arrays (shots, H, W)\n",
    "num_files = min(len(sig_paths), len(bg_paths))\n",
    "if NUM_SHOTS is not None:\n",
    "    num_files = min(num_files, NUM_SHOTS)\n",
    "\n",
    "RawInterferogramssig = np.zeros((num_files, frameshape[0], frameshape[1]), dtype=float)\n",
    "RawInterferogramsbg  = np.zeros((num_files, frameshape[0], frameshape[1]), dtype=float)\n",
    "\n",
    "for i in range(num_files):\n",
    "    s = imread(sig_paths[i]).astype(float)\n",
    "    b = imread(bg_paths[i]).astype(float)\n",
    "    # Convert color to grayscale if needed\n",
    "    if s.ndim == 3:\n",
    "        s = 0.2126 * s[...,0] + 0.7152 * s[...,1] + 0.0722 * s[...,2]\n",
    "    if b.ndim == 3:\n",
    "        b = 0.2126 * b[...,0] + 0.7152 * b[...,1] + 0.0722 * b[...,2]\n",
    "\n",
    "    RawInterferogramssig[i,:,:] = s\n",
    "    RawInterferogramsbg[i,:,:]  = b\n",
    "\n",
    "print(f\"Loaded {num_files} shots into arrays: sig {RawInterferogramssig.shape}\")\n",
    "\n",
    "# Quick visual check\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(RawInterferogramssig[0,:,:], cmap='gray')\n",
    "plt.title('Example signal interferogram (shot 0)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "def robust_envelope(signal,\n",
    "                    use_hilbert=True,\n",
    "                    smooth_sigma=2.0,\n",
    "                    savgol_win=11,\n",
    "                    savgol_poly=3,\n",
    "                    med_k=5,\n",
    "                    morph_size=9,\n",
    "                    peak_prom_frac=0.2,\n",
    "                    min_peak_distance=5):\n",
    "    \"\"\"\n",
    "    Return (upper_env, lower_env) for 1D `signal` robustly.\n",
    "    Strategy:\n",
    "      1) If use_hilbert: take analytic amplitude via Hilbert transform.\n",
    "      2) Smooth the amplitude (gaussian -> median -> savgol).\n",
    "      3) For upper env use the smoothed amplitude added to a (smoothed) center.\n",
    "      4) Also compute peak-based envelopes as a fallback and blend if necessary.\n",
    "    Parameters tuned in-call; adjust for your fringes.\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal, dtype=float)\n",
    "    t = np.arange(signal.size)\n",
    "\n",
    "    # 1) quick detrend/center to make amplitude estimate stable\n",
    "    sig_centered = signal - np.nanmean(signal)\n",
    "\n",
    "    # 2) amplitude from analytic signal (Hilbert)\n",
    "    amp = np.abs(hilbert(sig_centered)) if use_hilbert else None\n",
    "\n",
    "    if amp is None or np.all(np.isnan(amp)) or np.nanmax(amp)-np.nanmin(amp) < 1e-8:\n",
    "        # fallback later to peak-based method\n",
    "        amp = None\n",
    "\n",
    "    # 3) smooth the amplitude if available\n",
    "    if amp is not None:\n",
    "        amp_s = gaussian_filter1d(amp, sigma=smooth_sigma, mode='reflect')\n",
    "        amp_s = median_filter(amp_s, size=med_k)\n",
    "        # savgol requires odd window and be smaller than length\n",
    "        if savgol_win >= len(amp_s):\n",
    "            savgol_win = max(3, (len(amp_s) // 2) // 2 * 2 + 1)\n",
    "        try:\n",
    "            amp_s = savgol_filter(amp_s, window_length=savgol_win, polyorder=savgol_poly)\n",
    "        except Exception:\n",
    "            pass\n",
    "    else:\n",
    "        amp_s = None\n",
    "\n",
    "    # 4) estimate local centerline by low-pass filtering signal\n",
    "    center_lp = gaussian_filter1d(signal, sigma=smooth_sigma*2, mode='reflect')\n",
    "    center_lp = median_filter(center_lp, size=med_k)\n",
    "    if savgol_win < len(center_lp):\n",
    "        center_lp = savgol_filter(center_lp, window_length=savgol_win, polyorder=savgol_poly)\n",
    "\n",
    "    # 5) construct upper/lower using amp if available\n",
    "    if amp_s is not None:\n",
    "        upper = center_lp + amp_s\n",
    "        lower = center_lp - amp_s\n",
    "    else:\n",
    "        # Peak-based fallback (more like your original approach but smoothed)\n",
    "        prom = peak_prom_frac * (signal.max() - signal.min())\n",
    "        peaks, _ = find_peaks(sig_centered, prominence=prom, distance=min_peak_distance)\n",
    "        valleys, _ = find_peaks(-sig_centered, prominence=prom, distance=min_peak_distance)\n",
    "\n",
    "        # require at least two points to interpolate; otherwise fallback to global min/max\n",
    "        t_inds = np.arange(len(signal))\n",
    "        if len(peaks) >= 2 and len(valleys) >= 2:\n",
    "            upper = np.interp(t_inds, peaks, signal[peaks])\n",
    "            lower = np.interp(t_inds, valleys, signal[valleys])\n",
    "            # smooth those interpolated envelopes\n",
    "            upper = gaussian_filter1d(upper, sigma=smooth_sigma)\n",
    "            lower = gaussian_filter1d(lower, sigma=smooth_sigma)\n",
    "            upper = median_filter(upper, size=med_k)\n",
    "            lower = median_filter(lower, size=med_k)\n",
    "        else:\n",
    "            # very coarse fallback\n",
    "            upper = np.full_like(signal, np.nanmax(signal))\n",
    "            lower = np.full_like(signal, np.nanmin(signal))\n",
    "\n",
    "    # 6) morphological closing to remove local dips/spikes\n",
    "    try:\n",
    "        upper = grey_closing(upper, size=morph_size)\n",
    "        lower = grey_closing(lower, size=morph_size)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 7) final Savitzky smoothing to ensure differentiability for spline fits\n",
    "    try:\n",
    "        upper = savgol_filter(upper, window_length=min(len(upper)-1 if (len(upper)-1)%2==1 else len(upper)-2, savgol_win), polyorder=min(savgol_poly,2))\n",
    "        lower = savgol_filter(lower, window_length=min(len(lower)-1 if (len(lower)-1)%2==1 else len(lower)-2, savgol_win), polyorder=min(savgol_poly,2))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return upper, lower\n",
    "\n",
    "def fit_envelope_spline(t, upper, lower):\n",
    "    \"\"\"Safely fit cubic splines to envelopes (skips if contains NaN).\"\"\"\n",
    "    if np.any(np.isnan(upper)) or np.any(np.isnan(lower)):\n",
    "        return upper, lower\n",
    "    try:\n",
    "        u_fit = CubicSpline(t, upper)(t)\n",
    "        l_fit = CubicSpline(t, lower)(t)\n",
    "        return u_fit, l_fit\n",
    "    except Exception:\n",
    "        # fallback to smoothed arrays if spline fails\n",
    "        return upper, lower\n",
    "\n",
    "\n",
    "def remove_offset(signal: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Remove the mean offset from the signal.\n",
    "\n",
    "    Returns (centered_signal, offset)\n",
    "    \"\"\"\n",
    "    offset = float(np.nanmean(signal))\n",
    "    return signal - offset, offset\n",
    "\n",
    "\n",
    "def fit_envelopes(t: np.ndarray, upper_envelope: np.ndarray, lower_envelope: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Fit cubic splines to the provided envelopes and evaluate on t.\n",
    "\n",
    "    If envelopes contain NaNs (fallback), the function returns the original arrays.\n",
    "    \"\"\"\n",
    "    # If envelopes are constant or contain NaN, skip spline fit\n",
    "    if np.any(np.isnan(upper_envelope)) or np.any(np.isnan(lower_envelope)):\n",
    "        return upper_envelope, lower_envelope\n",
    "\n",
    "    upper_spline = CubicSpline(t, upper_envelope)\n",
    "    lower_spline = CubicSpline(t, lower_envelope)\n",
    "    return upper_spline(t), lower_spline(t)\n",
    "\n",
    "\n",
    "def extract_phase_from_column(signal: np.ndarray, plot_flag: bool = False) -> np.ndarray:\n",
    "    \"\"\"Extract an unwrapped phase from a 1D interferometric column using envelope demodulation.\n",
    "\n",
    "    Steps (high-level):\n",
    "    - estimate upper and lower envelopes\n",
    "    - compute centerline and iteratively remove it to flatten amplitude modulation\n",
    "    - normalise by the upper envelope to get a cosine-like signal in [-1, 1]\n",
    "    - arc-cos to obtain a triangular phase signal and fix downward slopes by mapping them into [0, 2pi]\n",
    "    - unwrap the phase\n",
    "\n",
    "    Returns the unwrapped phase array.\n",
    "    \"\"\"\n",
    "    t = np.arange(signal.size)\n",
    "\n",
    "    # 1) First pass envelopes\n",
    "    upper_env, lower_env = robust_envelope(signal)\n",
    "    upper_fit, lower_fit = fit_envelopes(t, upper_env, lower_env)\n",
    "    centerline = 0.5 * (upper_fit + lower_fit)\n",
    "\n",
    "    # 2) Remove centerline and repeat a few times to converge (your original used many iterations)\n",
    "    signal_iter = signal - centerline\n",
    "    centerline_iter = centerline\n",
    "    for _ in range(8):  # reduced iterations; increase if you still see residual modulation\n",
    "        upper_e, lower_e = robust_envelope(signal_iter)\n",
    "        upper_f, lower_f = fit_envelopes(t, upper_e, lower_e)\n",
    "        centerline_iter = 0.5 * (upper_f + lower_f)\n",
    "        signal_iter = signal_iter - centerline_iter\n",
    "\n",
    "    # 3) Final envelopes and normalisation\n",
    "    upper_e_final, lower_e_final = robust_envelope(signal_iter)\n",
    "    # Avoid division by zero\n",
    "    safe_upper = np.where(np.abs(upper_e_final) < 1e-6, np.nan, upper_e_final)\n",
    "    I_norm = signal_iter / safe_upper\n",
    "    # Clip into [-1, 1] to avoid numeric issues\n",
    "    I_norm = np.clip(I_norm, -1.0, 1.0)\n",
    "\n",
    "    # 4) Convert to phase via arccos; produces values in [0, pi]\n",
    "    phi = np.arccos(I_norm)\n",
    "\n",
    "    # 5) Fix segments where phi decreases (wrap correction used in your script)\n",
    "    # Find negative slopes and map the following point: phi[i+1] -> 2*pi - phi[i+1]\n",
    "    dphi = np.diff(phi)\n",
    "    neg_idx = np.where(dphi < 0)[0]\n",
    "    phi_mod = phi.copy()\n",
    "    if neg_idx.size > 0:\n",
    "        phi_mod[neg_idx + 1] = 2 * np.pi - phi_mod[neg_idx + 1]\n",
    "\n",
    "    # 6) Unwrap\n",
    "    # Replace NaNs (if any) before unwrap\n",
    "    valid = ~np.isnan(phi_mod)\n",
    "    phi_mod[valid] = np.unwrap(phi_mod[valid])\n",
    "\n",
    "    # Optional plotting for debug\n",
    "    if plot_flag:\n",
    "        fig, axs = plt.subplots(3, 2, figsize=(15, 8))\n",
    "        axs[0, 0].plot(t, signal, label='Original')\n",
    "        axs[0, 0].plot(t, upper_env, 'r--', label='Upper env')\n",
    "        axs[0, 0].plot(t, lower_env, 'b--', label='Lower env')\n",
    "        axs[0, 0].plot(t, centerline, 'm-', label='Centerline')\n",
    "        axs[0, 0].legend()\n",
    "        axs[0, 0].set_ylabel('pixel value')\n",
    "\n",
    "        axs[1, 0].plot(t, signal_iter, label='Iteratively flattened')\n",
    "        axs[1, 0].plot(t, upper_e_final, 'r--')\n",
    "        axs[1, 0].plot(t, lower_e_final, 'b--')\n",
    "        axs[1, 0].set_ylabel('pixel value')\n",
    "\n",
    "        axs[2, 0].plot(t, I_norm, label='Normalized signal')\n",
    "        axs[2, 0].set_ylabel('normalized')\n",
    "\n",
    "        axs[1, 1].plot(phi, label='raw arccos')\n",
    "        axs[1, 1].plot(phi_mod, label='after slope correction')\n",
    "        axs[1, 1].legend()\n",
    "\n",
    "        axs[2, 1].plot(phi_mod)\n",
    "        axs[2, 1].set_title('Unwrapped phase (after)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return phi_mod\n",
    "\n",
    "# Main processing loop: compute avg phase shift image (signal - background)\n",
    "shots_to_process = RawInterferogramssig.shape[0]\n",
    "H = frameshape[0]\n",
    "W = frameshape[1]\n",
    "\n",
    "phase_shifts = np.zeros((shots_to_process, H, W), dtype=float)\n",
    "\n",
    "for shot_idx in range(shots_to_process):\n",
    "    phase_img = np.zeros((H, W), dtype=float)\n",
    "    for row_idx in range(H):\n",
    "        plot_flag = (shot_idx == 0 and row_idx == 0)  # only plot the very first column for debugging\n",
    "        sig_col = RawInterferogramssig[shot_idx, row_idx, :]\n",
    "        bg_col  = RawInterferogramsbg[shot_idx, row_idx, :]\n",
    "\n",
    "        phase_sig = extract_phase_from_column(sig_col, plot_flag=plot_flag)\n",
    "        phase_bg  = extract_phase_from_column(bg_col, plot_flag=False)\n",
    "\n",
    "        # If extraction failed (NaNs) handle gracefully\n",
    "        if phase_sig is None or phase_bg is None:\n",
    "            phase_img[row_idx, :] = np.nan\n",
    "        else:\n",
    "            phase_img[row_idx, :] = phase_sig - phase_bg\n",
    "\n",
    "    phase_shifts[shot_idx] = phase_img\n",
    "    print(f\"Finished processing shot {shot_idx + 1}/{shots_to_process}\")\n",
    "\n",
    "# Average across shots\n",
    "avg_phase = np.nanmean(phase_shifts, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(avg_phase, cmap='RdBu', vmin=PHASE_DISPLAY_CLIM[0], vmax=PHASE_DISPLAY_CLIM[1])\n",
    "plt.colorbar(label='Phase shift (rad)')\n",
    "plt.title('Average phase shift image')\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved column-phase extraction with adaptive bandpass + Hilbert\n",
    "# Paste into your notebook cell after reading images (keeps RawInterferogramssig, RawInterferogramsbg, frameshape)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert, find_peaks, savgol_filter, butter, filtfilt\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter, grey_closing\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------\n",
    "# Parameters you can tune\n",
    "# ------------------------\n",
    "MODE = \"hilbert_direct\"   # \"hilbert_direct\" (recommended) or \"envelope_arccos\"\n",
    "POST_PHASE_SMOOTH_SIGMA = 1.0   # gaussian smoothing on unwrapped phase (pixels); 0 to disable\n",
    "MIN_PERIOD = 4          # minimum fringe period (pixels) to consider valid\n",
    "MAX_PERIOD = 200        # maximum fringe period (pixels) to consider valid\n",
    "BANDWIDTH_FACTOR = 0.6  # bandpass width fraction relative to central freq (0.6 -> ±30%)\n",
    "# envelope smoothing fractions (relative to period)\n",
    "ENV_GAUSS_SIGMA_FRAC = 0.35\n",
    "ENV_MEDIAN_K_FRAC    = 0.15\n",
    "ENV_SAVGOL_WIN_FRAC  = 1.5  # window length ~ 1.5 * period (odd)\n",
    "# safe defaults when carrier not found\n",
    "DEFAULT_SAVGOL_WIN = 11\n",
    "DEFAULT_GAUSS_SIGMA = 2.0\n",
    "\n",
    "# ------------------------\n",
    "# Utility functions\n",
    "# ------------------------\n",
    "def estimate_fringe_period(signal):\n",
    "    \"\"\"\n",
    "    Estimate dominant fringe period (in pixels) from the 1D signal using FFT.\n",
    "    Returns period (pixels) or None if unclear.\n",
    "    \"\"\"\n",
    "    s = np.asarray(signal, dtype=float)\n",
    "    n = s.size\n",
    "    if n < 8:\n",
    "        return None\n",
    "    # detrend simple\n",
    "    s0 = s - np.nanmean(s)\n",
    "    # window to reduce leakage\n",
    "    w = np.hanning(n)\n",
    "    S = np.fft.rfft(s0 * w)\n",
    "    ps = np.abs(S)**2\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0)  # cycles / pixel\n",
    "    # ignore DC\n",
    "    ps[0] = 0.0\n",
    "    # pick peak frequency (exclude very high freqs)\n",
    "    # convert to period = 1/freq\n",
    "    peak_idx = np.argmax(ps)\n",
    "    f0 = freqs[peak_idx]\n",
    "    if f0 <= 0:\n",
    "        return None\n",
    "    period = 1.0 / f0\n",
    "    if np.isnan(period) or period < MIN_PERIOD or period > MAX_PERIOD:\n",
    "        return None\n",
    "    return float(period)\n",
    "\n",
    "def butter_bandpass(low, high, fs=1.0, order=3):\n",
    "    # low, high in cycles/pixel (fs=1 pix^-1)\n",
    "    nyq = fs / 2.0\n",
    "    lowb = max(low / nyq, 1e-6)\n",
    "    highb = min(high / nyq, 0.999999)\n",
    "    if lowb >= highb:\n",
    "        # invalid, return None\n",
    "        return None, None\n",
    "    b, a = butter(order, [lowb, highb], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter_1d(signal, low, high, order=3):\n",
    "    b, a = butter_bandpass(low, high, fs=1.0, order=order)\n",
    "    if b is None:\n",
    "        return signal.copy()\n",
    "    # use filtfilt for zero-phase\n",
    "    try:\n",
    "        return filtfilt(b, a, signal, method=\"pad\")\n",
    "    except Exception:\n",
    "        # fallback to simple gaussian smoothing around removed low-frequency components\n",
    "        return gaussian_filter1d(signal, sigma=1.0, mode='reflect')\n",
    "\n",
    "def adaptive_env_params_from_period(period):\n",
    "    if period is None:\n",
    "        return {\n",
    "            \"savgol_win\": DEFAULT_SAVGOL_WIN,\n",
    "            \"gauss_sigma\": DEFAULT_GAUSS_SIGMA,\n",
    "            \"median_k\": int(max(3, 5)),\n",
    "        }\n",
    "    sav = int(max(3, round(ENV_SAVGOL_WIN_FRAC * period)))\n",
    "    if sav % 2 == 0:\n",
    "        sav += 1\n",
    "    medk = int(max(3, round(ENV_MEDIAN_K_FRAC * period)))\n",
    "    if medk % 2 == 0:\n",
    "        medk += 1\n",
    "    gauss = max(0.5, ENV_GAUSS_SIGMA_FRAC * period)\n",
    "    return {\"savgol_win\": max(3, min(sav, period*4)), \"gauss_sigma\": gauss, \"median_k\": medk}\n",
    "\n",
    "def smooth_envelope(amp, savgol_win, savgol_poly=3, med_k=5, gauss_sigma=2.0):\n",
    "    \"\"\"\n",
    "    Smooth amplitude (analytic) with median -> gaussian -> savgol.\n",
    "    Returns smoothed amplitude.\n",
    "    \"\"\"\n",
    "    a = amp.copy()\n",
    "    try:\n",
    "        a = median_filter(a, size=med_k)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        a = gaussian_filter1d(a, sigma=gauss_sigma, mode='reflect')\n",
    "    except Exception:\n",
    "        pass\n",
    "    # ensure savgol_win < len(a)\n",
    "    if savgol_win >= len(a):\n",
    "        savgol_win = max(3, (len(a) // 2) // 2 * 2 + 1)\n",
    "    try:\n",
    "        a = savgol_filter(a, window_length=savgol_win, polyorder=min(3, savgol_poly))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "# ------------------------\n",
    "# Phase extraction functions\n",
    "# ------------------------\n",
    "def extract_phase_hilbert_column(signal, do_plot=False):\n",
    "    \"\"\"\n",
    "    Recommended: bandpass around the fringe, compute analytic signal, take instantaneous phase.\n",
    "    \"\"\"\n",
    "    n = len(signal)\n",
    "    period = estimate_fringe_period(signal)\n",
    "    params = adaptive_env_params_from_period(period)\n",
    "\n",
    "    if period is None:\n",
    "        # try to fall back to some smoothing + hilbert\n",
    "        bp_low, bp_high = 0.005, 0.45  # very wide\n",
    "    else:\n",
    "        f0 = 1.0 / period\n",
    "        bw = f0 * BANDWIDTH_FACTOR\n",
    "        bp_low = max(0.0001, f0 - bw/2.0)\n",
    "        bp_high = min(0.4999, f0 + bw/2.0)\n",
    "\n",
    "    # bandpass the raw signal to isolate carrier\n",
    "    sig_bp = bandpass_filter_1d(signal, bp_low, bp_high, order=3)\n",
    "\n",
    "    # analytic signal\n",
    "    analytic = hilbert(sig_bp - np.nanmean(sig_bp))\n",
    "    inst_phase = np.angle(analytic)         # wrapped [-pi,pi]\n",
    "    inst_phase_unwrapped = np.unwrap(inst_phase)\n",
    "\n",
    "    # optional smoothing of the unwrapped phase (reduces high-frequency unwrap noise)\n",
    "    if POST_PHASE_SMOOTH_SIGMA > 0:\n",
    "        inst_phase_unwrapped = gaussian_filter1d(inst_phase_unwrapped, sigma=POST_PHASE_SMOOTH_SIGMA, mode='reflect')\n",
    "\n",
    "    if do_plot:\n",
    "        t = np.arange(n)\n",
    "        amp = np.abs(analytic)\n",
    "        amp_s = smooth_envelope(amp, params[\"savgol_win\"], med_k=params[\"median_k\"], gauss_sigma=params[\"gauss_sigma\"])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(t, signal, label='raw')\n",
    "        plt.plot(t, sig_bp, label='bandpassed')\n",
    "        plt.legend()\n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(t, amp, label='hilbert amp (raw)')\n",
    "        plt.plot(t, amp_s, label='amp smoothed')\n",
    "        plt.legend()\n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(t, inst_phase_unwrapped, label='inst phase unwrapped')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return inst_phase_unwrapped\n",
    "\n",
    "def extract_phase_envelope_arccos_column(signal, do_plot=False):\n",
    "    \"\"\"\n",
    "    Envelope method retained but improved:\n",
    "      - bandpass first (like above) to help envelope find peaks for amplitude\n",
    "      - use analytic amplitude smoothed as envelope\n",
    "      - normalise and arccos -> unwrap (like your earlier method)\n",
    "    \"\"\"\n",
    "    n = len(signal)\n",
    "    period = estimate_fringe_period(signal)\n",
    "    params = adaptive_env_params_from_period(period)\n",
    "\n",
    "    # bandpass to isolate carrier component used to compute amplitude\n",
    "    if period is None:\n",
    "        bp_low, bp_high = 0.005, 0.45\n",
    "    else:\n",
    "        f0 = 1.0 / period\n",
    "        bw = f0 * BANDWIDTH_FACTOR\n",
    "        bp_low = max(0.0001, f0 - bw/2.0)\n",
    "        bp_high = min(0.4999, f0 + bw/2.0)\n",
    "\n",
    "    sig_bp = bandpass_filter_1d(signal, bp_low, bp_high, order=3)\n",
    "    analytic = hilbert(sig_bp - np.nanmean(sig_bp))\n",
    "    amp = np.abs(analytic)\n",
    "    amp_s = smooth_envelope(amp, params[\"savgol_win\"], med_k=params[\"median_k\"], gauss_sigma=params[\"gauss_sigma\"])\n",
    "\n",
    "    # centerline: slow-varying part of raw signal (not the bandpassed)\n",
    "    center_lp = gaussian_filter1d(signal, sigma=max(1, params[\"gauss_sigma\"]*2), mode='reflect')\n",
    "    center_lp = median_filter(center_lp, size=params[\"median_k\"])\n",
    "    try:\n",
    "        center_lp = savgol_filter(center_lp, window_length=min(len(center_lp)-1 if (len(center_lp)-1)%2==1 else len(center_lp)-2, params[\"savgol_win\"]), polyorder=3)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Build upper/lower from smoothed amplitude\n",
    "    upper = center_lp + amp_s\n",
    "    lower = center_lp - amp_s\n",
    "\n",
    "    # Optional morphological closing (heals small dips)\n",
    "    try:\n",
    "        upper = grey_closing(upper, size=7)\n",
    "        lower = grey_closing(lower, size=7)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Normalize raw signal (after removing center)\n",
    "    signal_centered = signal - center_lp\n",
    "    safe_upper = np.where(np.abs(upper - center_lp) < 1e-9, np.nan, (upper - center_lp))\n",
    "    I_norm = signal_centered / safe_upper\n",
    "    I_norm = np.clip(I_norm, -1.0, 1.0)\n",
    "\n",
    "    phi = np.arccos(I_norm)\n",
    "    dphi = np.diff(phi)\n",
    "    neg_idx = np.where(dphi < 0)[0]\n",
    "    phi_mod = phi.copy()\n",
    "    if neg_idx.size > 0:\n",
    "        phi_mod[neg_idx + 1] = 2*np.pi - phi_mod[neg_idx + 1]\n",
    "\n",
    "    valid = ~np.isnan(phi_mod)\n",
    "    if np.any(valid):\n",
    "        phi_mod[valid] = np.unwrap(phi_mod[valid])\n",
    "\n",
    "    if POST_PHASE_SMOOTH_SIGMA > 0:\n",
    "        phi_mod = gaussian_filter1d(phi_mod, sigma=POST_PHASE_SMOOTH_SIGMA, mode='reflect')\n",
    "\n",
    "    if do_plot:\n",
    "        t = np.arange(n)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(t, signal, label='raw')\n",
    "        plt.plot(t, upper, '--', label='upper')\n",
    "        plt.plot(t, lower, '--', label='lower')\n",
    "        plt.legend()\n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(t, amp, label='hilbert amp (raw)')\n",
    "        plt.plot(t, amp_s, label='amp smoothed')\n",
    "        plt.legend()\n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(t, phi_mod, label='unwrapped phase')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return phi_mod\n",
    "\n",
    "# ------------------------\n",
    "# Main processing loop using improved extraction\n",
    "# ------------------------\n",
    "shots_to_process = RawInterferogramssig.shape[0]\n",
    "H = frameshape[0]\n",
    "W = frameshape[1]\n",
    "phase_shifts = np.zeros((shots_to_process, H, W), dtype=float)\n",
    "\n",
    "for shot_idx in range(shots_to_process):\n",
    "    phase_img = np.zeros((H, W), dtype=float)\n",
    "    for row_idx in range(H):\n",
    "        # debug-plot only first row of first shot if you need to inspect\n",
    "        plot_flag = (shot_idx == 0 and row_idx == 0)\n",
    "        sig_col = RawInterferogramssig[shot_idx, row_idx, :].astype(float)\n",
    "        bg_col  = RawInterferogramsbg[shot_idx, row_idx, :].astype(float)\n",
    "\n",
    "        if MODE == \"hilbert_direct\":\n",
    "            phase_sig = extract_phase_hilbert_column(sig_col, do_plot=plot_flag)\n",
    "            phase_bg  = extract_phase_hilbert_column(bg_col, do_plot=False)\n",
    "        else:\n",
    "            phase_sig = extract_phase_envelope_arccos_column(sig_col, do_plot=plot_flag)\n",
    "            phase_bg  = extract_phase_envelope_arccos_column(bg_col, do_plot=False)\n",
    "\n",
    "        # subtract (signal - background)\n",
    "        if phase_sig is None or phase_bg is None or phase_sig.shape != phase_bg.shape:\n",
    "            phase_img[row_idx, :] = np.nan\n",
    "        else:\n",
    "            phase_img[row_idx, :] = phase_sig - phase_bg\n",
    "\n",
    "    phase_shifts[shot_idx] = phase_img\n",
    "    print(f\"Finished shot {shot_idx+1}/{shots_to_process}\")\n",
    "\n",
    "avg_phase = np.nanmean(phase_shifts, axis=0)\n",
    "\n",
    "# Plot result\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(avg_phase, cmap='RdBu', vmin=-0.05, vmax=0.05)\n",
    "plt.colorbar(label='Phase shift (rad)')\n",
    "plt.title('Average phase shift (improved)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with column magnitude rejection + nearest-good-column replacement\n",
    "# Paste into a Jupyter cell and run.\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "from scipy.signal import hilbert, savgol_filter, butter, filtfilt\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter, grey_closing, gaussian_filter\n",
    "from scipy.interpolate import SmoothBivariateSpline\n",
    "from math import ceil\n",
    "\n",
    "# ------------------------\n",
    "# USER PARAMETERS (edit)\n",
    "# ------------------------\n",
    "sig_path = Path(r\"C:\\Users\\sann7609\\Documents\\Oxford\\ChannelAnalysis_CALA_Sept25_minisforum\\vanilla_interferometry\\for_vanilla_80mbar_Bdel582_t0\\Interferometry2\\sig\")\n",
    "bg_path  = Path(r\"C:\\Users\\sann7609\\Documents\\Oxford\\ChannelAnalysis_CALA_Sept25_minisforum\\vanilla_interferometry\\for_vanilla_80mbar_Bdel582_t0\\Interferometry2\\bg\")\n",
    "SIG_PATTERN = \".tiff\"\n",
    "BG_PATTERN  = \".tiff\"\n",
    "FILES_TO_LOAD = 5          # how many sig/bg pairs to load/process\n",
    "MODE = \"hilbert_direct\"    # \"hilbert_direct\" or \"envelope_arccos\"\n",
    "POST_PHASE_SMOOTH_SIGMA = 1.0\n",
    "\n",
    "# The channel masks you provided (rows to mask out for fitting)\n",
    "CHANNEL_MASKS = [(200, 370), (650, 820)]\n",
    "\n",
    "# Spline fit degree/smoothing control\n",
    "SPLINE_KX = 3\n",
    "SPLINE_KY = 3\n",
    "SPLINE_SMTH_MULTIPLIER = 0.8  # larger => smoother surface\n",
    "\n",
    "# Ridge fallback degree & regularization\n",
    "POLY_DEGREE_FALLBACK = 2\n",
    "RIDGE_LAMBDA = 1e-6\n",
    "\n",
    "# Display options\n",
    "COLORMAP = 'RdBu'\n",
    "PHASE_VMIN, PHASE_VMAX = -0.4, 0.4\n",
    "SHOW_PER_SHOT_PLOTS = True\n",
    "SHOW_AVERAGE_PLOTS  = True\n",
    "\n",
    "# Tolerances for column validation (existing)\n",
    "MIN_VALID_POINTS_PER_COLUMN = 10   # minimum non-NaN points in a vertical column to be considered valid\n",
    "MIN_STD_FOR_VALID_COLUMN = 1e-6    # if std < this, consider column invalid (likely constant/failed)\n",
    "\n",
    "# NEW: column magnitude based rejection\n",
    "COLUMN_MAG_THRESHOLD = 0.5        # approximate maximum expected absolute phase (radians)\n",
    "COLUMN_MAG_FACTOR_MAX = 1.2       # hard limit: if any |value| > threshold * factor_max -> reject\n",
    "COLUMN_MEDIAN_FACTOR = 0.9        # if median(|col|) > threshold * COLUMN_MEDIAN_FACTOR -> reject (looser)\n",
    "\n",
    "# ------------------------\n",
    "# Utilities and extraction routines (unchanged)\n",
    "# ------------------------\n",
    "def to_gray_if_needed(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 3 and arr.shape[2] >= 3:\n",
    "        return 0.2126*arr[...,0] + 0.7152*arr[...,1] + 0.0722*arr[...,2]\n",
    "    return arr\n",
    "\n",
    "def estimate_fringe_period(signal, MIN_PERIOD=4, MAX_PERIOD=200):\n",
    "    s = np.asarray(signal, dtype=float)\n",
    "    n = s.size\n",
    "    if n < 8:\n",
    "        return None\n",
    "    s0 = s - np.nanmean(s)\n",
    "    w = np.hanning(n)\n",
    "    S = np.fft.rfft(s0 * w)\n",
    "    ps = np.abs(S)**2\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0)\n",
    "    ps[0] = 0.0\n",
    "    peak_idx = np.argmax(ps)\n",
    "    f0 = freqs[peak_idx]\n",
    "    if f0 <= 0:\n",
    "        return None\n",
    "    period = 1.0 / f0\n",
    "    if np.isnan(period) or period < MIN_PERIOD or period > MAX_PERIOD:\n",
    "        return None\n",
    "    return float(period)\n",
    "\n",
    "def butter_bandpass(low, high, fs=1.0, order=3):\n",
    "    nyq = fs / 2.0\n",
    "    lowb = max(low / nyq, 1e-9)\n",
    "    highb = min(high / nyq, 0.999999)\n",
    "    if lowb >= highb:\n",
    "        return None, None\n",
    "    from scipy.signal import butter\n",
    "    b, a = butter(order, [lowb, highb], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter_1d(signal, low, high, order=3):\n",
    "    b, a = butter_bandpass(low, high, fs=1.0, order=order)\n",
    "    if b is None:\n",
    "        return signal.copy()\n",
    "    try:\n",
    "        return filtfilt(b, a, signal, method='pad')\n",
    "    except Exception:\n",
    "        return gaussian_filter1d(signal, sigma=1.0, mode='reflect')\n",
    "\n",
    "def adaptive_env_params_from_period(period, ENV_GAUSS_SIGMA_FRAC=0.35, ENV_MEDIAN_K_FRAC=0.15, ENV_SAVGOL_WIN_FRAC=1.5,\n",
    "                                   DEFAULT_SAVGOL_WIN=11, DEFAULT_GAUSS_SIGMA=2.0):\n",
    "    if period is None:\n",
    "        return {\"savgol_win\": DEFAULT_SAVGOL_WIN, \"gauss_sigma\": DEFAULT_GAUSS_SIGMA, \"median_k\": int(max(3,5))}\n",
    "    sav = int(max(3, round(ENV_SAVGOL_WIN_FRAC * period)))\n",
    "    if sav % 2 == 0:\n",
    "        sav += 1\n",
    "    medk = int(max(3, round(ENV_MEDIAN_K_FRAC * period)))\n",
    "    if medk % 2 == 0:\n",
    "        medk += 1\n",
    "    gauss = max(0.5, ENV_GAUSS_SIGMA_FRAC * period)\n",
    "    return {\"savgol_win\": max(3, min(sav, int(period*4))), \"gauss_sigma\": gauss, \"median_k\": medk}\n",
    "\n",
    "def smooth_envelope(amp, savgol_win, savgol_poly=3, med_k=5, gauss_sigma=2.0):\n",
    "    a = amp.copy()\n",
    "    try:\n",
    "        a = median_filter(a, size=med_k)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        a = gaussian_filter1d(a, sigma=gauss_sigma, mode='reflect')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if savgol_win >= len(a):\n",
    "        savgol_win = max(3, (len(a) // 2) // 2 * 2 + 1)\n",
    "    try:\n",
    "        a = savgol_filter(a, window_length=savgol_win, polyorder=min(3, savgol_poly))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "# primary extraction (bandpass + hilbert)\n",
    "def extract_hilbert_col_main(signal, BANDWIDTH_FACTOR=0.6, POST_PHASE_SMOOTH_SIGMA=1.0):\n",
    "    n = len(signal)\n",
    "    period = estimate_fringe_period(signal)\n",
    "    params = adaptive_env_params_from_period(period)\n",
    "    if period is None:\n",
    "        bp_low, bp_high = 0.005, 0.45\n",
    "    else:\n",
    "        f0 = 1.0 / period\n",
    "        bw = f0 * BANDWIDTH_FACTOR\n",
    "        bp_low = max(0.0001, f0 - bw/2.0)\n",
    "        bp_high = min(0.4999, f0 + bw/2.0)\n",
    "    sig_bp = bandpass_filter_1d(signal, bp_low, bp_high, order=3)\n",
    "    analytic = hilbert(sig_bp - np.nanmean(sig_bp))\n",
    "    inst_phase = np.angle(analytic)\n",
    "    inst_phase_unwrapped = np.unwrap(inst_phase)\n",
    "    if POST_PHASE_SMOOTH_SIGMA > 0:\n",
    "        inst_phase_unwrapped = gaussian_filter1d(inst_phase_unwrapped, sigma=POST_PHASE_SMOOTH_SIGMA, mode='reflect')\n",
    "    result = {\"phase\": inst_phase_unwrapped, \"bandpassed\": sig_bp, \"analytic\": analytic,\n",
    "              \"amp_s\": smooth_envelope(np.abs(analytic), params[\"savgol_win\"], med_k=params[\"median_k\"], gauss_sigma=params[\"gauss_sigma\"]),\n",
    "              \"period\": period}\n",
    "    return result\n",
    "\n",
    "# fallback: direct hilbert (no bandpass)\n",
    "def extract_hilbert_col_fallback(signal, POST_PHASE_SMOOTH_SIGMA=1.0):\n",
    "    analytic = hilbert(signal - np.nanmean(signal))\n",
    "    inst_phase_unwrapped = np.unwrap(np.angle(analytic))\n",
    "    if POST_PHASE_SMOOTH_SIGMA > 0:\n",
    "        inst_phase_unwrapped = gaussian_filter1d(inst_phase_unwrapped, sigma=POST_PHASE_SMOOTH_SIGMA, mode='reflect')\n",
    "    return {\"phase\": inst_phase_unwrapped, \"bandpassed\": signal, \"analytic\": analytic, \"amp_s\": np.abs(analytic), \"period\": None}\n",
    "\n",
    "def extract_envelope_arccos_col(signal, BANDWIDTH_FACTOR=0.6, POST_PHASE_SMOOTH_SIGMA=1.0):\n",
    "    # improved envelope method\n",
    "    n = len(signal)\n",
    "    period = estimate_fringe_period(signal)\n",
    "    params = adaptive_env_params_from_period(period)\n",
    "    if period is None:\n",
    "        bp_low, bp_high = 0.005, 0.45\n",
    "    else:\n",
    "        f0 = 1.0 / period\n",
    "        bw = f0 * BANDWIDTH_FACTOR\n",
    "        bp_low = max(0.0001, f0 - bw/2.0)\n",
    "        bp_high = min(0.4999, f0 + bw/2.0)\n",
    "    sig_bp = bandpass_filter_1d(signal, bp_low, bp_high, order=3)\n",
    "    analytic = hilbert(sig_bp - np.nanmean(sig_bp))\n",
    "    amp = np.abs(analytic)\n",
    "    amp_s = smooth_envelope(amp, params[\"savgol_win\"], med_k=params[\"median_k\"], gauss_sigma=params[\"gauss_sigma\"])\n",
    "    center_lp = gaussian_filter1d(signal, sigma=max(1, params[\"gauss_sigma\"]*2), mode='reflect')\n",
    "    center_lp = median_filter(center_lp, size=params[\"median_k\"])\n",
    "    try:\n",
    "        center_lp = savgol_filter(center_lp, window_length=min(len(center_lp)-1 if (len(center_lp)-1)%2==1 else len(center_lp)-2, params[\"savgol_win\"]), polyorder=3)\n",
    "    except Exception:\n",
    "        pass\n",
    "    upper = center_lp + amp_s\n",
    "    lower = center_lp - amp_s\n",
    "    try:\n",
    "        upper = grey_closing(upper, size=7)\n",
    "        lower = grey_closing(lower, size=7)\n",
    "    except Exception:\n",
    "        pass\n",
    "    signal_centered = signal - center_lp\n",
    "    safe_upper = np.where(np.abs(upper - center_lp) < 1e-9, np.nan, (upper - center_lp))\n",
    "    I_norm = signal_centered / safe_upper\n",
    "    I_norm = np.clip(I_norm, -1.0, 1.0)\n",
    "    phi = np.arccos(I_norm)\n",
    "    dphi = np.diff(phi)\n",
    "    neg_idx = np.where(dphi < 0)[0]\n",
    "    phi_mod = phi.copy()\n",
    "    if neg_idx.size > 0:\n",
    "        phi_mod[neg_idx + 1] = 2*np.pi - phi_mod[neg_idx + 1]\n",
    "    valid = ~np.isnan(phi_mod)\n",
    "    if np.any(valid):\n",
    "        phi_mod[valid] = np.unwrap(phi_mod[valid])\n",
    "    if POST_PHASE_SMOOTH_SIGMA > 0:\n",
    "        phi_mod = gaussian_filter1d(phi_mod, sigma=POST_PHASE_SMOOTH_SIGMA, mode='reflect')\n",
    "    return {\"phase\": phi_mod, \"bandpassed\": sig_bp, \"analytic\": analytic, \"amp\": amp, \"amp_s\": amp_s, \"upper\": upper, \"lower\": lower, \"center_lp\": center_lp, \"I_norm\": I_norm, \"period\": period}\n",
    "\n",
    "# wrapper per-column that applies fallback automatically\n",
    "def extract_column_phase(signal, mode=MODE):\n",
    "    if mode == \"hilbert_direct\":\n",
    "        out = extract_hilbert_col_main(signal)\n",
    "        phase = out.get('phase', None)\n",
    "        if phase is None or phase.shape[0] != signal.shape[0] or np.sum(~np.isnan(phase)) < MIN_VALID_POINTS_PER_COLUMN:\n",
    "            out = extract_hilbert_col_fallback(signal)\n",
    "        return out\n",
    "    else:\n",
    "        out = extract_envelope_arccos_col(signal)\n",
    "        phase = out.get('phase', None)\n",
    "        if phase is None or phase.shape[0] != signal.shape[0] or np.sum(~np.isnan(phase)) < MIN_VALID_POINTS_PER_COLUMN:\n",
    "            out = extract_hilbert_col_fallback(signal)\n",
    "        return out\n",
    "\n",
    "# ------------------------\n",
    "# Load files and compute phase maps (vertical columns)\n",
    "# ------------------------\n",
    "sig_files = sorted([p for p in sig_path.glob(f\"*{SIG_PATTERN}*\")])\n",
    "bg_files  = sorted([p for p in bg_path.glob(f\"*{BG_PATTERN}*\")])\n",
    "if len(sig_files) == 0 or len(bg_files) == 0:\n",
    "    raise FileNotFoundError(\"No signal/background files found — check sig_path/bg_path and patterns.\")\n",
    "\n",
    "files_to_use = min(FILES_TO_LOAD, len(sig_files), len(bg_files))\n",
    "print(f\"Loading {files_to_use} sig/bg pairs\")\n",
    "\n",
    "first_img = to_gray_if_needed(imread(sig_files[0])).astype(float)\n",
    "if first_img.ndim == 2:\n",
    "    H, W = first_img.shape\n",
    "else:\n",
    "    H, W = first_img.shape[0], first_img.shape[1]\n",
    "\n",
    "RawInterferogramssig = np.zeros((files_to_use, H, W), dtype=float)\n",
    "RawInterferogramsbg  = np.zeros((files_to_use, H, W), dtype=float)\n",
    "\n",
    "for i in range(files_to_use):\n",
    "    s = to_gray_if_needed(imread(sig_files[i]).astype(float))\n",
    "    b = to_gray_if_needed(imread(bg_files[i]).astype(float))\n",
    "    RawInterferogramssig[i] = s\n",
    "    RawInterferogramsbg[i] = b\n",
    "\n",
    "print(\"Loaded shapes:\", RawInterferogramssig.shape)\n",
    "\n",
    "# Compute phase maps\n",
    "phase_maps = np.full((files_to_use, H, W), np.nan, dtype=float)\n",
    "\n",
    "for sidx in range(files_to_use):\n",
    "    ph_map = np.full((H, W), np.nan, dtype=float)\n",
    "    for col_idx in range(W):\n",
    "        sig_col = RawInterferogramssig[sidx, :, col_idx].astype(float)\n",
    "        bg_col  = RawInterferogramsbg[sidx, :, col_idx].astype(float)\n",
    "        out_sig = extract_column_phase(sig_col, mode=MODE)\n",
    "        out_bg  = extract_column_phase(bg_col, mode=MODE)\n",
    "        phs = out_sig.get('phase', None)\n",
    "        phb = out_bg.get('phase', None)\n",
    "        if phs is None or phb is None or phs.shape != phb.shape:\n",
    "            ph_map[:, col_idx] = np.nan\n",
    "        else:\n",
    "            ph_map[:, col_idx] = phs - phb\n",
    "    phase_maps[sidx] = ph_map\n",
    "    print(f\"Computed phase map for shot {sidx+1}/{files_to_use}\")\n",
    "\n",
    "# ------------------------\n",
    "# Build mask from CHANNEL_MASKS (True = masked/excluded from fit)\n",
    "# ------------------------\n",
    "mask = np.zeros((H, W), dtype=bool)\n",
    "for (ystart, yend) in CHANNEL_MASKS:\n",
    "    y0 = int(max(0, ystart)); y1 = int(min(H, yend))\n",
    "    if y1 > y0:\n",
    "        mask[y0:y1, :] = True\n",
    "\n",
    "# ------------------------\n",
    "# Robust 2D fit per-shot using SmoothBivariateSpline with outlier rejection\n",
    "# ------------------------\n",
    "def robust_2d_spline_fit(Z, mask_bool, kx=3, ky=3, smth_mult=1.0):\n",
    "    H, W = Z.shape\n",
    "    yy, xx = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
    "    xx_flat = xx.ravel(); yy_flat = yy.ravel(); z_flat = Z.ravel()\n",
    "    valid = (~mask_bool.ravel()) & (~np.isnan(z_flat))\n",
    "    if valid.sum() < 20:\n",
    "        return None, False, \"too few valid points\"\n",
    "    x_valid = xx_flat[valid]; y_valid = yy_flat[valid]; z_valid = z_flat[valid]\n",
    "\n",
    "    med = np.nanmedian(z_valid)\n",
    "    std = np.nanstd(z_valid)\n",
    "    if std == 0 or np.isnan(std):\n",
    "        std = 1.0\n",
    "    thresh = 3.0\n",
    "    inlier_mask = np.abs(z_valid - med) <= (thresh * std)\n",
    "    if inlier_mask.sum() < max(20, int(0.3 * valid.sum())):\n",
    "        thresh = 4.0\n",
    "        inlier_mask = np.abs(z_valid - med) <= (thresh * std)\n",
    "\n",
    "    x_in = x_valid[inlier_mask]; y_in = y_valid[inlier_mask]; z_in = z_valid[inlier_mask]\n",
    "    n_in = x_in.size\n",
    "    if n_in < 20:\n",
    "        return None, False, \"too few inliers after trimming\"\n",
    "\n",
    "    s_val = smth_mult * (np.nanstd(z_in)**2) * n_in\n",
    "\n",
    "    try:\n",
    "        spline = SmoothBivariateSpline(x_in, y_in, z_in, kx=kx, ky=ky, s=s_val)\n",
    "        xx_grid = np.arange(W)\n",
    "        yy_grid = np.arange(H)\n",
    "        Z_fit = spline(xx_grid, yy_grid)  # (len(xx_grid), len(yy_grid))\n",
    "        Z_fit = Z_fit.T\n",
    "        return Z_fit, True, {\"n_in\": n_in, \"s_val\": s_val}\n",
    "    except Exception as e:\n",
    "        return None, False, f\"spline failed: {e}\"\n",
    "\n",
    "def fit_2d_ridge_poly(Z, mask_bool, deg=2, lam=1e-6):\n",
    "    H, W = Z.shape\n",
    "    yy, xx = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
    "    xx_flat = xx.ravel(); yy_flat = yy.ravel(); z_flat = Z.ravel()\n",
    "    valid = (~mask_bool.ravel()) & (~np.isnan(z_flat))\n",
    "    x = xx_flat[valid]; y = yy_flat[valid]; z = z_flat[valid]\n",
    "    if z.size < 10:\n",
    "        return None, False, \"too few points\"\n",
    "    terms = []\n",
    "    for d in range(deg+1):\n",
    "        for i in range(d+1):\n",
    "            j = d - i\n",
    "            terms.append((i, j))\n",
    "    A = np.vstack([ (x**i) * (y**j) for (i,j) in terms ]).T\n",
    "    ATA = A.T.dot(A)\n",
    "    M = ATA.shape[0]\n",
    "    ATA_reg = ATA + lam * np.eye(M)\n",
    "    rhs = A.T.dot(z)\n",
    "    coeffs = np.linalg.solve(ATA_reg, rhs)\n",
    "    xx_all = xx_flat; yy_all = yy_flat\n",
    "    A_full = np.vstack([ (xx_all**i) * (yy_all**j) for (i,j) in terms ]).T\n",
    "    z_fit_flat = A_full.dot(coeffs)\n",
    "    return z_fit_flat.reshape(H, W), True, {\"deg\": deg, \"lam\": lam}\n",
    "\n",
    "# Apply fits and subtract\n",
    "fitted_surfaces = np.full_like(phase_maps, np.nan)\n",
    "corrected_maps = np.full_like(phase_maps, np.nan)\n",
    "fit_details = []\n",
    "\n",
    "for sidx in range(files_to_use):\n",
    "    Z = phase_maps[sidx]\n",
    "    Z_fit, ok, info = robust_2d_spline_fit(Z, mask, kx=SPLINE_KX, ky=SPLINE_KY, smth_mult=SPLINE_SMTH_MULTIPLIER)\n",
    "    if not ok:\n",
    "        Z_fit, ok2, info2 = fit_2d_ridge_poly(Z, mask, deg=POLY_DEGREE_FALLBACK, lam=RIDGE_LAMBDA)\n",
    "        if not ok2:\n",
    "            print(f\"Shot {sidx+1}: both spline and poly fallback failed ({info}; {info2}). Leaving NaNs.\")\n",
    "            fitted_surfaces[sidx] = np.nan\n",
    "            corrected_maps[sidx] = np.nan\n",
    "            fit_details.append({\"sidx\": sidx, \"method\": \"failed\", \"info\": (info, info2)})\n",
    "            continue\n",
    "        else:\n",
    "            fitted_surfaces[sidx] = Z_fit\n",
    "            corrected_maps[sidx] = Z - Z_fit\n",
    "            fit_details.append({\"sidx\": sidx, \"method\": \"ridge_poly\", \"info\": info2})\n",
    "    else:\n",
    "        fitted_surfaces[sidx] = Z_fit\n",
    "        corrected_maps[sidx] = Z - Z_fit\n",
    "        fit_details.append({\"sidx\": sidx, \"method\": \"spline\", \"info\": info})\n",
    "\n",
    "# ------------------------\n",
    "# Fill partial NaNs along rows (small gaps) - linear interpolation across columns per row\n",
    "# ------------------------\n",
    "def fill_nan_columns_by_row_interpolation(map2d):\n",
    "    H, W = map2d.shape\n",
    "    out = map2d.copy()\n",
    "    x = np.arange(W)\n",
    "    for yi in range(H):\n",
    "        row = out[yi, :]\n",
    "        nan_mask = np.isnan(row)\n",
    "        if np.all(nan_mask):\n",
    "            continue\n",
    "        if np.any(nan_mask):\n",
    "            valid_idx = np.where(~nan_mask)[0]\n",
    "            valid_vals = row[valid_idx]\n",
    "            filled = np.interp(x, valid_idx, valid_vals, left=valid_vals[0], right=valid_vals[-1])\n",
    "            out[yi, nan_mask] = filled[nan_mask]\n",
    "    return out\n",
    "\n",
    "# ------------------------\n",
    "# Detect bad columns (by count/std/magnitude) and replace by nearest good column\n",
    "# ------------------------\n",
    "def find_bad_columns(map2d, min_valid_points=MIN_VALID_POINTS_PER_COLUMN, min_std=MIN_STD_FOR_VALID_COLUMN,\n",
    "                     mag_thresh=COLUMN_MAG_THRESHOLD, mag_factor_max=COLUMN_MAG_FACTOR_MAX, mag_median_factor=COLUMN_MEDIAN_FACTOR):\n",
    "    \"\"\"\n",
    "    Return boolean array (W,) where True means column is considered 'bad' and should be replaced.\n",
    "    \"\"\"\n",
    "    H, W = map2d.shape\n",
    "    bad = np.zeros(W, dtype=bool)\n",
    "    for j in range(W):\n",
    "        col = map2d[:, j]\n",
    "        valid_mask = ~np.isnan(col)\n",
    "        valid_count = int(valid_mask.sum())\n",
    "        if valid_count < min_valid_points:\n",
    "            bad[j] = True\n",
    "            continue\n",
    "        col_std = float(np.nanstd(col))\n",
    "        if col_std < min_std:\n",
    "            bad[j] = True\n",
    "            continue\n",
    "        # magnitude checks\n",
    "        max_abs = float(np.nanmax(np.abs(col)))\n",
    "        med_abs = float(np.nanmedian(np.abs(col)))\n",
    "        if max_abs > (mag_thresh * mag_factor_max):\n",
    "            bad[j] = True\n",
    "            continue\n",
    "        if med_abs > (mag_thresh * mag_median_factor):\n",
    "            bad[j] = True\n",
    "            continue\n",
    "    return bad\n",
    "\n",
    "def replace_bad_columns_by_nearest(map2d, bad_mask):\n",
    "    \"\"\"\n",
    "    Replace columns marked in bad_mask with nearest good column copy.\n",
    "    Returns (out_map, replaced_indices)\n",
    "    \"\"\"\n",
    "    H, W = map2d.shape\n",
    "    out = map2d.copy()\n",
    "    good_idx = np.where(~bad_mask)[0]\n",
    "    if good_idx.size == 0:\n",
    "        # no good columns -> nothing to replace\n",
    "        return out, np.where(bad_mask)[0]\n",
    "    for j in np.where(bad_mask)[0]:\n",
    "        # find nearest good col\n",
    "        distances = np.abs(good_idx - j)\n",
    "        nearest_pos = np.argmin(distances)\n",
    "        nearest_col = good_idx[nearest_pos]\n",
    "        out[:, j] = out[:, nearest_col]\n",
    "    return out, np.where(bad_mask)[0]\n",
    "\n",
    "# Apply small row interpolation then column rejection+replacement per shot\n",
    "replacement_summary = []\n",
    "\n",
    "for sidx in range(files_to_use):\n",
    "    if np.all(np.isnan(phase_maps[sidx])):\n",
    "        replacement_summary.append({\"sidx\": sidx, \"replaced_cols\": []})\n",
    "        continue\n",
    "    # small-gap interpolation\n",
    "    phase_maps[sidx] = fill_nan_columns_by_row_interpolation(phase_maps[sidx])\n",
    "    if not np.all(np.isnan(fitted_surfaces[sidx])):\n",
    "        fitted_surfaces[sidx] = fill_nan_columns_by_row_interpolation(fitted_surfaces[sidx])\n",
    "    if not np.all(np.isnan(corrected_maps[sidx])):\n",
    "        corrected_maps[sidx] = fill_nan_columns_by_row_interpolation(corrected_maps[sidx])\n",
    "\n",
    "    # detect bad columns in corrected map (prefer corrected map since it's what you'll analyse)\n",
    "    bad_cols = find_bad_columns(corrected_maps[sidx], min_valid_points=MIN_VALID_POINTS_PER_COLUMN,\n",
    "                                min_std=MIN_STD_FOR_VALID_COLUMN, mag_thresh=COLUMN_MAG_THRESHOLD,\n",
    "                                mag_factor_max=COLUMN_MAG_FACTOR_MAX, mag_median_factor=COLUMN_MEDIAN_FACTOR)\n",
    "    # also ensure we don't accidentally mark as bad columns inside masked rows only (if whole column masked) - but previous checks handle NaNs\n",
    "    # Replace bad columns in all maps consistently\n",
    "    phase_maps[sidx], replaced_phase_cols = replace_bad_columns_by_nearest(phase_maps[sidx], bad_cols)\n",
    "    if not np.all(np.isnan(fitted_surfaces[sidx])):\n",
    "        fitted_surfaces[sidx], _ = replace_bad_columns_by_nearest(fitted_surfaces[sidx], bad_cols)\n",
    "    if not np.all(np.isnan(corrected_maps[sidx])):\n",
    "        corrected_maps[sidx], _ = replace_bad_columns_by_nearest(corrected_maps[sidx], bad_cols)\n",
    "\n",
    "    replacement_summary.append({\"sidx\": sidx, \"replaced_cols\": replaced_phase_cols.tolist(), \"n_replaced\": len(replaced_phase_cols)})\n",
    "\n",
    "# Recompute averages AFTER filling / replacement\n",
    "avg_before = np.nanmean(phase_maps[:files_to_use], axis=0)\n",
    "avg_fit    = np.nanmean(fitted_surfaces[:files_to_use], axis=0)\n",
    "avg_after  = np.nanmean(corrected_maps[:files_to_use], axis=0)\n",
    "avg_corrected_map = avg_after.copy()\n",
    "\n",
    "# ------------------------\n",
    "# Plotting: per-shot (original w/mask, fitted surface, corrected) and averages\n",
    "# All plots flipped vertically via origin='lower'\n",
    "# ------------------------\n",
    "for sidx in range(files_to_use):\n",
    "    if not SHOW_PER_SHOT_PLOTS:\n",
    "        break\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,5))\n",
    "    # Original with mask overlay\n",
    "    im0 = axs[0].imshow(phase_maps[sidx], cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    axs[0].set_title(f\"Shot {sidx+1} — Original phase map (after fixes)\")\n",
    "    mask_overlay = np.ma.masked_where(~mask, mask)\n",
    "    axs[0].imshow(mask_overlay, cmap='gray', alpha=0.25, origin='lower')\n",
    "    axs[0].set_axis_off()\n",
    "    plt.colorbar(im0, ax=axs[0], fraction=0.046)\n",
    "\n",
    "    # Fitted surface (use same cmap/limits for direct comparison)\n",
    "    if not np.all(np.isnan(fitted_surfaces[sidx])):\n",
    "        im1 = axs[1].imshow(fitted_surfaces[sidx], cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    else:\n",
    "        im1 = axs[1].imshow(np.zeros((H,W)), cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "        axs[1].text(0.5, 0.5, 'fit failed', transform=axs[1].transAxes, ha='center')\n",
    "    axs[1].set_title(\"Fitted 2D surface (same cmap)\")\n",
    "    axs[1].set_axis_off()\n",
    "    plt.colorbar(im1, ax=axs[1], fraction=0.046)\n",
    "\n",
    "    # Corrected map\n",
    "    im2 = axs[2].imshow(corrected_maps[sidx], cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    axs[2].set_title(\"Corrected map (original − fitted)\")\n",
    "    axs[2].set_axis_off()\n",
    "    plt.colorbar(im2, ax=axs[2], fraction=0.046)\n",
    "\n",
    "    suppl = f\"Shot {sidx+1}: method={fit_details[sidx]['method']} info={fit_details[sidx]['info']}. Replaced {replacement_summary[sidx]['n_replaced']} bad cols.\"\n",
    "    plt.suptitle(suppl)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Average plots\n",
    "if SHOW_AVERAGE_PLOTS:\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,5))\n",
    "    im0 = axs[0].imshow(avg_before, cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    axs[0].set_title(\"Average before subtraction\")\n",
    "    axs[0].imshow(np.ma.masked_where(~mask, mask), cmap='gray', alpha=0.25, origin='lower')\n",
    "    axs[0].set_axis_off()\n",
    "    plt.colorbar(im0, ax=axs[0], fraction=0.046)\n",
    "\n",
    "    im1 = axs[1].imshow(avg_fit, cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    axs[1].set_title(\"Average fitted surface (same cmap)\")\n",
    "    axs[1].set_axis_off()\n",
    "    plt.colorbar(im1, ax=axs[1], fraction=0.046)\n",
    "\n",
    "    im2 = axs[2].imshow(avg_after, cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower')\n",
    "    axs[2].set_title(\"Average after subtraction (final avg corrected map)\")\n",
    "    axs[2].set_axis_off()\n",
    "    plt.colorbar(im2, ax=axs[2], fraction=0.046)\n",
    "\n",
    "    plt.suptitle(f\"Averages across first {files_to_use} shots — spline_mult={SPLINE_SMTH_MULTIPLIER}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Done.\\nFit details per shot:\")\n",
    "for d in fit_details:\n",
    "    print(d)\n",
    "print(\"\\nColumn replacement summary per shot:\")\n",
    "for r in replacement_summary:\n",
    "    print(f\"Shot {r['sidx']+1}: replaced {r['n_replaced']} columns: {r['replaced_cols']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fft_phase = np.loadtxt(r'C:\\Users\\sann7609\\Documents\\Oxford\\ChannelAnalysis_CALA_Sept25_minisforum\\channel_analysis_250910_largeFFT\\phase_maps\\80mbar_Bdel582_t0\\Interferometry2\\AvgPhase.txt')\n",
    "\n",
    "phasemax=0.3\n",
    "# Show final averaged corrected map\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,6))\n",
    "axs[0].imshow(avg_corrected_map, cmap=COLORMAP, vmin=-phasemax, vmax=phasemax, origin='lower')\n",
    "#plt.colorbar(label='Phase (rad)')\n",
    "\n",
    "axs[1].imshow(fft_phase, cmap='RdBu', vmin=-phasemax, vmax=phasemax,origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,6))\n",
    "sig_img = RawInterferogramssig[0,:,:]\n",
    "bg_img  = RawInterferogramsbg[0,:,:]\n",
    "H = sig_img.shape[0]\n",
    "W = sig_img.shape[1]\n",
    "pixsize=1.06e-6 #microns\n",
    "extent = [0,W*pixsize*1e6,0,H*pixsize*1e6] # in meters\n",
    "axs[0].imshow(RawInterferogramssig[0,:,:], cmap='gray', origin='lower',extent=extent)\n",
    "axs[1].imshow(RawInterferogramsbg[0,:,:], cmap='gray', origin='lower',extent=extent)\n",
    "axs[0].set_xlabel('X (microns)')\n",
    "axs[0].set_ylabel('Y (microns)')\n",
    "axs[1].set_xlabel('X (microns)')\n",
    "axs[0].text(s='a) Signal',x=50,y=1000,color='yellow',fontsize=14)\n",
    "axs[1].text(s='b) Background',x=50,y=1000,color='yellow',fontsize=14)\n",
    "axs[1].set_yticklabels([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'c:\\Users\\sann7609\\Documents\\Oxford\\Thesis\\images\\Interferograms_sig_bg.png',dpi=300,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full updated plotting cell with x-limits for c)-f)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter, gaussian_filter\n",
    "from scipy.signal import savgol_filter, hilbert\n",
    "import warnings\n",
    "\n",
    "# --------------- USER TWEAKS ---------------\n",
    "REF_SHOT = 0            # which shot to show (0-based)\n",
    "REF_COL = None          # which column to inspect; None -> center column\n",
    "ZOOM_FRACTION = 0.30    # portion of image height to zoom into stacked plots\n",
    "FIG_W = 8.0             # figure width (inches)\n",
    "FIG_H = 11.0            # figure height (inches)\n",
    "POST_PHASE_SMOOTH_SIGMA = 1.0\n",
    "PIXEL_MICRONS_X = 1359.0\n",
    "PIXEL_MICRONS_Y = 1088.0\n",
    "COLORMAP = 'RdBu'\n",
    "PHASE_VMIN, PHASE_VMAX = -0.4, 0.4\n",
    "\n",
    "# Optional: display-only smoothing sigma for presentation (set to 0 to disable)\n",
    "DISPLAY_SMOOTH_SIGMA = 0.0\n",
    "\n",
    "sig_color = 'blue'\n",
    "bg_color = 'orange'\n",
    "# -------------------------------------------\n",
    "\n",
    "# small helpers (reused)\n",
    "def bandpass_filter_1d(signal, low, high, order=3):\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    nyq = 0.5\n",
    "    lowb = max(low / nyq, 1e-9)\n",
    "    highb = min(high / nyq, 0.999999)\n",
    "    if lowb >= highb:\n",
    "        return signal.copy()\n",
    "    b, a = butter(order, [lowb, highb], btype='band')\n",
    "    try:\n",
    "        return filtfilt(b, a, signal, method='pad')\n",
    "    except Exception:\n",
    "        from scipy.ndimage import gaussian_filter1d\n",
    "        return gaussian_filter1d(signal, sigma=1.0, mode='reflect')\n",
    "\n",
    "def smooth_envelope(amp, savgol_win=11, med_k=5, gauss_sigma=2.0):\n",
    "    a = np.asarray(amp).copy()\n",
    "    try:\n",
    "        a = median_filter(a, size=max(1, med_k))\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        a = gaussian_filter1d(a, sigma=max(0.5, gauss_sigma), mode='reflect')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if savgol_win >= len(a):\n",
    "        savgol_win = max(3, (len(a) // 2) // 2 * 2 + 1)\n",
    "    try:\n",
    "        a = savgol_filter(a, window_length=int(savgol_win), polyorder=min(3,2))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "def extract_envelope_arccos_col_wrapped(signal, bp_low=0.005, bp_high=0.45,\n",
    "                                        savgol_win=11, med_k=5, gauss_sigma=2.0,\n",
    "                                        post_smooth=0.0, renorm_pct=99):\n",
    "    sig_bp = bandpass_filter_1d(signal, bp_low, bp_high)\n",
    "    analytic = hilbert(sig_bp - np.nanmean(sig_bp))\n",
    "    amp = np.abs(analytic)\n",
    "    amp_s = smooth_envelope(amp, savgol_win=savgol_win, med_k=med_k, gauss_sigma=gauss_sigma)\n",
    "\n",
    "    center_lp = gaussian_filter1d(signal, sigma=max(1, gauss_sigma*2), mode='reflect')\n",
    "    center_lp = median_filter(center_lp, size=max(1, med_k))\n",
    "    try:\n",
    "        center_lp = savgol_filter(center_lp, window_length=min(len(center_lp)-1 if (len(center_lp)-1)%2==1 else len(center_lp)-2, savgol_win), polyorder=3)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    upper = center_lp + amp_s\n",
    "    lower = center_lp - amp_s\n",
    "    centerline = 0.5*(upper+lower)\n",
    "    amplitude = 0.5*(upper-lower)\n",
    "    safe_amp = np.where(np.abs(amplitude) < 1e-9, np.nan, amplitude)\n",
    "    I_norm_raw = (signal - centerline) / safe_amp\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        pct_val = np.nanpercentile(np.abs(I_norm_raw), renorm_pct) if np.any(np.isfinite(I_norm_raw)) else 1.0\n",
    "    scale = float(pct_val) if (np.isfinite(pct_val) and pct_val > 0) else 1.0\n",
    "    if scale < 1e-6:\n",
    "        scale = 1.0\n",
    "    I_norm = I_norm_raw / scale\n",
    "    I_norm_clipped = np.clip(I_norm, -1.0, 1.0)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        phi_tri_wrapped = np.arccos(I_norm_clipped)\n",
    "\n",
    "    dphi = np.diff(phi_tri_wrapped)\n",
    "    neg_idx = np.where(dphi < 0)[0]\n",
    "    phi_tri_corr_wrapped = phi_tri_wrapped.copy()\n",
    "    if neg_idx.size > 0:\n",
    "        for idx in neg_idx:\n",
    "            v = phi_tri_corr_wrapped[idx+1]\n",
    "            phi_tri_corr_wrapped[idx+1] = (2*np.pi - v) % (2*np.pi)\n",
    "\n",
    "    if post_smooth > 0:\n",
    "        phi_tri_corr_wrapped = gaussian_filter1d(phi_tri_corr_wrapped, sigma=post_smooth, mode='reflect')\n",
    "\n",
    "    return {\n",
    "        'sig_bp': sig_bp, 'analytic': analytic, 'amp': amp, 'amp_s': amp_s,\n",
    "        'upper': upper, 'lower': lower, 'centerline': centerline,\n",
    "        'I_norm_raw': I_norm_raw, 'I_norm': I_norm, 'I_norm_clipped': I_norm_clipped,\n",
    "        'scale_used': scale, 'phi_tri_wrapped': phi_tri_wrapped, 'phi_tri_corr_wrapped': phi_tri_corr_wrapped\n",
    "    }\n",
    "\n",
    "# ----------------- ensure pipeline outputs exist -----------------\n",
    "try:\n",
    "    RawSig = RawInterferogramssig\n",
    "    RawBg = RawInterferogramsbg\n",
    "    phase_maps   # processed sig-bg per-shot maps (from pipeline)\n",
    "    corrected_maps\n",
    "    fitted_surfaces\n",
    "    mask\n",
    "except NameError as e:\n",
    "    raise RuntimeError(\"Pipeline outputs (phase_maps, corrected_maps, fitted_surfaces, mask, RawInterferogramssig) not found. Run the pipeline cell first.\") from e\n",
    "\n",
    "shots_avail = RawSig.shape[0]\n",
    "H, W = RawSig.shape[1], RawSig.shape[2]\n",
    "REF_SHOT = int(np.clip(REF_SHOT, 0, shots_avail-1))\n",
    "if REF_COL is None:\n",
    "    REF_COL = W // 2\n",
    "else:\n",
    "    REF_COL = int(np.clip(REF_COL, 0, W-1))\n",
    "\n",
    "sig_img = RawSig[REF_SHOT]\n",
    "bg_img  = RawBg[REF_SHOT]\n",
    "# Use pipeline outputs for the single-shot displays\n",
    "raw_single_shot_map = phase_maps[REF_SHOT]\n",
    "corrected_single_shot = corrected_maps[REF_SHOT]\n",
    "fitted_shot = fitted_surfaces[REF_SHOT] if (fitted_surfaces is not None and fitted_surfaces.shape[0] > REF_SHOT) else np.full((H,W), np.nan)\n",
    "if 'avg_corrected_map' not in globals():\n",
    "    avg_corrected_map = np.nanmean(corrected_maps, axis=0)\n",
    "\n",
    "def maybe_smooth_display(arr, sigma):\n",
    "    if sigma and sigma > 0:\n",
    "        arr2 = arr.copy()\n",
    "        nanmask = np.isnan(arr2)\n",
    "        arr2[nanmask] = 0.0\n",
    "        arr2 = gaussian_filter(arr2, sigma=sigma)\n",
    "        arr2[nanmask] = np.nan\n",
    "        return arr2\n",
    "    return arr\n",
    "\n",
    "display_raw_map = maybe_smooth_display(raw_single_shot_map, DISPLAY_SMOOTH_SIGMA)\n",
    "display_corrected = maybe_smooth_display(corrected_single_shot, DISPLAY_SMOOTH_SIGMA)\n",
    "display_fitted = maybe_smooth_display(fitted_shot, DISPLAY_SMOOTH_SIGMA)\n",
    "display_avg = maybe_smooth_display(avg_corrected_map, DISPLAY_SMOOTH_SIGMA)\n",
    "\n",
    "# pick reference column vectors\n",
    "sig_col = sig_img[:, REF_COL].astype(float)\n",
    "bg_col  = bg_img[:, REF_COL].astype(float)\n",
    "\n",
    "# compute envelope extraction for reference column to populate stacked panels\n",
    "period_est = None\n",
    "n = len(sig_col)\n",
    "if n >= 8:\n",
    "    s0 = sig_col - np.nanmean(sig_col)\n",
    "    w = np.hanning(n)\n",
    "    S = np.fft.rfft(s0*w)\n",
    "    ps = np.abs(S)**2\n",
    "    ps[0] = 0.0\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0)\n",
    "    peak_idx = np.argmax(ps)\n",
    "    f0 = freqs[peak_idx] if peak_idx < len(freqs) else 0.02\n",
    "    if f0 > 0:\n",
    "        period_est = 1.0 / f0\n",
    "\n",
    "if period_est is None:\n",
    "    bp_low, bp_high = 0.005, 0.45\n",
    "else:\n",
    "    f0 = 1.0/period_est\n",
    "    bp_low = max(0.0005, f0*0.6)\n",
    "    bp_high = min(0.49, f0*1.4)\n",
    "\n",
    "env = extract_envelope_arccos_col_wrapped(sig_col, bp_low=bp_low, bp_high=bp_high,\n",
    "                                          savgol_win=max(11, int(round((period_est or 8)*1.5))),\n",
    "                                          med_k=5, gauss_sigma=max(1, (period_est*0.35) if period_est else 2),\n",
    "                                          post_smooth=POST_PHASE_SMOOTH_SIGMA, renorm_pct=99)\n",
    "\n",
    "# zoom indices\n",
    "zoom_h = int(max(8, round(H * ZOOM_FRACTION)))\n",
    "center_idx = H//2\n",
    "if np.any(env['amp_s'] > 0):\n",
    "    center_idx = int(np.nanargmax(env['amp_s']))\n",
    "zoom_lo = max(0, center_idx - zoom_h//2)\n",
    "zoom_hi = min(H, zoom_lo + zoom_h)\n",
    "zoom_slice = slice(zoom_lo, zoom_hi)\n",
    "t_zoom = np.arange(zoom_lo, zoom_hi)\n",
    "\n",
    "# ---------------- GridSpec layout & plotting ----------------\n",
    "# Now 6 rows: top images, four stacked small rows (c-f), bottom row with two images (g,h)\n",
    "nrows = 6\n",
    "ncols = 2\n",
    "h_top = 3.2\n",
    "h_stack_row = 0.7\n",
    "height_ratios = [h_top] + [h_stack_row]*4 + [h_top]\n",
    "width_ratios = [1,1]\n",
    "\n",
    "fig = plt.figure(figsize=(FIG_W, FIG_H))\n",
    "gs = gridspec.GridSpec(nrows=nrows, ncols=ncols, figure=fig,\n",
    "                       height_ratios=height_ratios, width_ratios=width_ratios)\n",
    "\n",
    "# Top images (signal, background)\n",
    "ax_a = fig.add_subplot(gs[0,0])\n",
    "ax_b = fig.add_subplot(gs[0,1])\n",
    "\n",
    "# stacked zoomed plots (c-f) spanning both columns\n",
    "ax_c = fig.add_subplot(gs[1, :])\n",
    "ax_d = fig.add_subplot(gs[2, :], sharex=ax_c)\n",
    "ax_e = fig.add_subplot(gs[3, :], sharex=ax_c)\n",
    "ax_f = fig.add_subplot(gs[4, :], sharex=ax_c)\n",
    "\n",
    "# --- Set custom x-limits for stacked plots (c–f) ---\n",
    "# Use the zoomed row index range so c-f show the same window as the vertical markers\n",
    "ax_c.set_xlim(t_zoom[0], t_zoom[-1])\n",
    "\n",
    "# bottom 1 row with 2 images (g,h)\n",
    "ax_g = fig.add_subplot(gs[5,0])\n",
    "ax_h = fig.add_subplot(gs[5,1])\n",
    "\n",
    "extent = [0, PIXEL_MICRONS_X, 0, PIXEL_MICRONS_Y]\n",
    "\n",
    "# Top interferograms (square pixels)\n",
    "ax_a.imshow(sig_img, cmap='gray', origin='lower', extent=extent, aspect='equal')\n",
    "ax_b.imshow(bg_img,  cmap='gray', origin='lower', extent=extent, aspect='equal')\n",
    "\n",
    "# Colored vertical segment markers that correspond to line colors in c)\n",
    "col_x_um = (REF_COL + 0.5) * (PIXEL_MICRONS_X / W)\n",
    "y0_um = (zoom_lo) * (PIXEL_MICRONS_Y / H)\n",
    "y1_um = (zoom_hi-1) * (PIXEL_MICRONS_Y / H)\n",
    "\n",
    "offset_um = (PIXEL_MICRONS_X / W) * 0.6\n",
    "ax_a.plot([col_x_um - offset_um, col_x_um - offset_um], [y0_um, y1_um], color=sig_color, linestyle='-', linewidth=2)\n",
    "ax_a.plot([col_x_um + offset_um, col_x_um + offset_um], [y0_um, y1_um], color=sig_color, linestyle='-', linewidth=2)\n",
    "ax_b.plot([col_x_um - offset_um, col_x_um - offset_um], [y0_um, y1_um], color=bg_color, linestyle='-', linewidth=2)\n",
    "ax_b.plot([col_x_um + offset_um, col_x_um + offset_um], [y0_um, y1_um], color=bg_color, linestyle='-', linewidth=2)\n",
    "\n",
    "# Put x ticks and labels on top of a) and b)\n",
    "ax_a.xaxis.set_label_position('top'); ax_a.xaxis.tick_top()\n",
    "ax_b.xaxis.set_label_position('top'); ax_b.xaxis.tick_top()\n",
    "\n",
    "ax_a.set_xlabel(\"x (μm)\"); ax_a.set_ylabel(\"y (μm)\")\n",
    "ax_b.set_xlabel(\"x (μm)\")\n",
    "# nicer tick spacing: ~200 µm steps on x, ~250 µm on y\n",
    "x_ticks = np.arange(0, PIXEL_MICRONS_X + 1, 200)\n",
    "y_ticks = np.arange(0, PIXEL_MICRONS_Y + 1, 250)\n",
    "\n",
    "ax_a.set_xticks(x_ticks)\n",
    "ax_a.set_yticks(y_ticks)\n",
    "ax_b.set_xticks(x_ticks)\n",
    "ax_b.set_yticks([])\n",
    "\n",
    "\n",
    "# stacked plots c-f (zoomed) with matched colors for signal/bg\n",
    "ax_c.plot(t_zoom, sig_col[zoom_slice], label='signal', lw=1.1, color=sig_color)\n",
    "ax_c.plot(t_zoom, bg_col[zoom_slice], label='background', lw=1.1, alpha=0.85, color=bg_color)\n",
    "ax_c.set_ylabel(\"pixel val\")\n",
    "\n",
    "ax_d.plot(t_zoom, sig_col[zoom_slice], lw=0.9, color=sig_color, label='signal')\n",
    "ax_d.plot(t_zoom, env['upper'][zoom_slice], '--', label='upper env', color='red')\n",
    "ax_d.plot(t_zoom, env['lower'][zoom_slice], '--', label='lower env', color='red')\n",
    "ax_d.plot(t_zoom, env['centerline'][zoom_slice], label='centerline', color='magenta')\n",
    "ax_d.set_ylabel(\"pixel val\")\n",
    "\n",
    "ax_e.plot(t_zoom, env['I_norm'][zoom_slice]*1.2, lw=0.9, label=f'I_norm (scale={env[\"scale_used\"]:.2f})', color='k')\n",
    "ax_e.set_ylim(-1.2, 1.2)\n",
    "\n",
    "\n",
    "phi_tri = env['phi_tri_wrapped'][zoom_slice] / np.pi\n",
    "phi_corr = env['phi_tri_corr_wrapped'][zoom_slice] / np.pi\n",
    "ax_f.plot(t_zoom, phi_tri*1.2, lw=0.9, label='tri (wrapped)/π', color='k')\n",
    "ax_f.plot(t_zoom, phi_corr*1.2, lw=0.9, linestyle='--', label='slope-corr (wrapped)/π', color='magenta')\n",
    "ax_f.set_ylabel(\"Phase\")\n",
    "ymin = np.nanmin(np.concatenate([phi_tri, phi_corr]))\n",
    "ymax = np.nanmax(np.concatenate([phi_tri, phi_corr]))\n",
    "yticks = np.linspace(np.floor(ymin), np.ceil(ymax), min(5, max(2, int(np.ceil(ymax)-np.floor(ymin)+1))))\n",
    "ax_f.set_yticks(yticks)\n",
    "ylbls = []\n",
    "for v in yticks:\n",
    "    if abs(v - round(v)) < 1e-6:\n",
    "        ylbls.append(f\"{int(round(v))}π\")\n",
    "    else:\n",
    "        ylbls.append(f\"{v:.2f}π\")\n",
    "ax_f.set_yticklabels(ylbls)\n",
    "ax_f.set_xlabel(\"row (pixel)\")\n",
    "\n",
    "# ---------------- Bottom 2 images only (g,h) ----------------\n",
    "im_g = ax_g.imshow(display_raw_map, cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower', extent=extent, aspect='equal')\n",
    "ax_g.set_xlabel(\"x (μm)\"); ax_g.set_ylabel(\"y (μm)\")\n",
    "if mask is not None:\n",
    "    mo = np.ma.masked_where(~mask, mask)\n",
    "    ax_g.imshow(mo, cmap='gray', alpha=0.25, origin='lower', extent=extent, aspect='equal')\n",
    "\n",
    "im_h = ax_h.imshow(display_corrected, cmap=COLORMAP, vmin=PHASE_VMIN, vmax=PHASE_VMAX, origin='lower', extent=extent, aspect='equal')\n",
    "ax_h.set_xlabel(\"x (μm)\"); ax_h.set_yticks([])\n",
    "\n",
    "# hide redundant y-ticks on right column top plot\n",
    "ax_b.set_yticks([]); ax_h.set_yticks([])\n",
    "\n",
    "# colorbar aligned to bottom pair\n",
    "# colorbar aligned precisely to subplot h)\n",
    "pos_h = ax_h.get_position()\n",
    "cbar_x = pos_h.x1 + 0.008  # a bit closer\n",
    "cbar_y = 0.08\n",
    "cbar_w = 0.018             # slightly thinner\n",
    "cbar_w = 0.02              # width of colorbar\n",
    "cbar_h = pos_h.height*1.15      # match height of h)\n",
    "cax = fig.add_axes([cbar_x, cbar_y, cbar_w, cbar_h])\n",
    "cbar = fig.colorbar(im_h, cax=cax)\n",
    "cbar.set_label('Phase shift [rad]')\n",
    "\n",
    "\n",
    "# final layout tuning: smaller gap above a/b and slightly larger vertical space between panels a-f\n",
    "plt.subplots_adjust(\n",
    "    left=0.06,\n",
    "    right=0.88,\n",
    "    top=0.95,      # bring top of figure down -> less space above a,b\n",
    "    bottom=0.04,\n",
    "    wspace=0.02,\n",
    "    hspace=0.0     # slightly larger vertical gaps between stacked panels\n",
    ")\n",
    "\n",
    "ax_a.text(s='a) raw interferogram: signal',x=80,y=950, color='white', fontsize=14)\n",
    "ax_a.text(s=' lineout\\nlocation',x=700,y=200, color='white', fontsize=14)\n",
    "\n",
    "ax_b.text(s='b) raw interferogram:\\n    background',x=80,y=870, color='white', fontsize=14)\n",
    "ax_b.text(s=' lineout\\nlocation',x=700,y=200, color='white', fontsize=14)\n",
    "\n",
    "ax_c.text(s='c) zoomed lineout:',x=zoom_lo+10,y=np.nanmax(sig_col[zoom_slice])*1.1, color='black', fontsize=12)\n",
    "ax_c.text(s='signal',x=zoom_lo+10+75,y=np.nanmax(sig_col[zoom_slice])*1.1, color=sig_color, fontsize=12)\n",
    "ax_c.text(s='&',x=zoom_lo+10+100,y=np.nanmax(sig_col[zoom_slice])*1.1, color='black', fontsize=12)\n",
    "ax_c.text(s='background',x=zoom_lo+10+108,y=np.nanmax(sig_col[zoom_slice])*1.1, color=bg_color, fontsize=12)\n",
    "ax_c.set_ylim(np.nanmin(sig_col[zoom_slice])*0.9, np.nanmax(sig_col[zoom_slice])*1.4)\n",
    "\n",
    "ax_d.text(s='d)',x=zoom_lo+10,y=np.nanmax(sig_col[zoom_slice])*1.1, color='black', fontsize=12)\n",
    "ax_d.text(s='envelopes',x=zoom_lo+23,y=np.nanmax(sig_col[zoom_slice])*1.1, color='red', fontsize=12)\n",
    "ax_d.text(s='&',x=zoom_lo+65,y=np.nanmax(sig_col[zoom_slice])*1.1, color='black', fontsize=12)\n",
    "ax_d.text(s='centerline',x=zoom_lo+74,y=np.nanmax(sig_col[zoom_slice])*1.1, color='magenta', fontsize=12)\n",
    "ax_d.set_ylim(np.nanmin(sig_col[zoom_slice])*0.9, np.nanmax(sig_col[zoom_slice])*1.4)\n",
    "\n",
    "ax_e.text(s='e) normalized lineout',x=zoom_lo+10,y=1.3, color='black', fontsize=12)\n",
    "ax_e.set_ylim(-1, 1.99)\n",
    "\n",
    "ax_f.text(s='f) phase before unwrapping: triangular &',x=zoom_lo+10,y=np.nanmax(phi_corr)*1.25, color='black', fontsize=12)\n",
    "ax_f.text(s='slope-corrected',x=zoom_lo+174,y=np.nanmax(phi_corr)*1.25, color='magenta', fontsize=12)\n",
    "ax_f.set_ylim(np.nanmin(phi_corr)*0.9, np.nanmax(phi_corr)*1.6)\n",
    "\n",
    "ax_g.text(s='g) single-shot raw phase map',x=60,y=1000, color='black', fontsize=14)\n",
    "ax_g.text(s='mask for background fit',x=600,y=240, color='black', fontsize=10)\n",
    "\n",
    "ax_h.text(s='h) background-subtracted\\n   phase map',x=60,y=900, color='black', fontsize=14)\n",
    "\n",
    "plt.savefig(r'c:\\Users\\sann7609\\Documents\\Oxford\\Thesis\\images\\fringe_normalization_figure.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
